{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task for Today  \n",
    "\n",
    "## Concrete Crack Image Detection  \n",
    "\n",
    "Given *images of concrete surfaces*, let's try to detect **cracks** in the concrete.\n",
    "\n",
    "We will use a TensorFlow CNN to make our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download unter https://datanizing.com/crack-images.7z\n",
    "\n",
    "Unter Colab dann\n",
    "```!unzip crack-images.7z```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dir = Path('crack-images/Positive')\n",
    "negative_dir = Path('crack-images/Negative')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_df(image_dir, label):\n",
    "    filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name='Filepath').astype(str)\n",
    "    labels = pd.Series(label, name='Label', index=filepaths.index)\n",
    "    df = pd.concat([filepaths, labels], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_df = generate_df(positive_dir, label=\"POSITIVE\")\n",
    "negative_df = generate_df(negative_dir, label=\"NEGATIVE\")\n",
    "\n",
    "all_df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    all_df.sample(6000, random_state=1),\n",
    "    train_size=0.7,\n",
    "    shuffle=True,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_gen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(120, 120),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = train_gen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(120, 120),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_data = train_gen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='Filepath',\n",
    "    y_col='Label',\n",
    "    target_size=(120, 120),\n",
    "    color_mode='rgb',\n",
    "    class_mode='binary',\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(120, 120, 3))\n",
    "x = tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    history.history,\n",
    "    y=['loss', 'val_loss'],\n",
    "    labels={'index': \"Epoch\", 'value': \"Loss\"},\n",
    "    title=\"Training and Validation Loss Over Time\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    \n",
    "    results = model.evaluate(test_data, verbose=0)\n",
    "    loss = results[0]\n",
    "    acc = results[1]\n",
    "    \n",
    "    print(\"    Test Loss: {:.5f}\".format(loss))\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(acc * 100))\n",
    "    \n",
    "    y_pred = np.squeeze((model.predict(test_data) >= 0.5).astype(int))\n",
    "    cm = confusion_matrix(test_data.labels, y_pred)\n",
    "    clr = classification_report(test_data.labels, y_pred, target_names=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n",
    "    plt.xticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "    plt.yticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Classification Report:\\n----------------------\\n\", clr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Every Day  \n",
    "\n",
    "This notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n",
    "\n",
    "***\n",
    "\n",
    "Check it out!  \n",
    "https://youtu.be/eaa-7HLcAnQ"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 414522,
     "sourceId": 792851,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30056,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "baywiss",
   "language": "python",
   "name": "baywiss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
